{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maryantonopoulou/datastories_for_emme/blob/main/exercise7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Σκοπός αυτής της άσκησης είναι να φτιάξετε scrapers για 9 sites (ENA ο καθένας/καθεμιά).\n",
        "\n",
        "Με αυτό τον τρόπο, θα έχετε όλοι μαζί, 10 scrapers (μαζί με αυτόν που έφτιαξα εγώ για την καθημερινή), έναν για καθένα από 10 διαφορετικά sites. Έτσι, θα μπορείτε να τους χρησιμοποιήσετε για να φέρετε δεδομένα από διαφορετικά sites, σχετικά με το θέμα που θα διαλέξετε για την τελική σας εργασία, ώστε να μπορείτε να κάνετε συγκρίσεις."
      ],
      "metadata": {
        "id": "5ih3oay5xlNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Για να φτιάξετε τον scraper, μελετήστε και ακολουθήστε τα βήματα κατασκευής scraper που περιγράφονται σε αυτό το notebook: https://colab.research.google.com/drive/1F5DB56h9YcFXcnkr3b6y_0W63XjJ1mCI?usp=sharing\n",
        "\n",
        "Εκεί περιγράφεται λεπτομερώς ένας τρόπος κατασκευής ενός scraper για όλα (περίπου) τα teaser pages της Καθημερινής.\n",
        "\n",
        "**Το τελικό αποτέλεσμα της εργασίας σας θα είναι σαν τον scraper της Kαθημερινής** που θα βρείτε εδώ: https://colab.research.google.com/drive/112h9nSqAf9lLhez_ABd8ARx0Ks23eczu?usp=sharing"
      ],
      "metadata": {
        "id": "OtOuMs-hy_7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επειδή όπως είπαμε (και θα διαβάσετε και στο notebook) δεν σκραπάρονται όλα τα sites με το requests και για να μην ψάχνετε και χαωθείτε, σας παραθέτω 14 sites με τα οποία μπορείτε να δουλέψετε."
      ],
      "metadata": {
        "id": "RbeTZ5vKz2Va"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ο παρακάτω κώδικας μπαίνει σε ένα-ένα όλα τα 14 sites, φέρνει την πρώτη σελίδα που έχει όλα τα άρθρα και εφόσον όλα πάνε καλά μετράει πόσα άρθρα έχει η σελίδα."
      ],
      "metadata": {
        "id": "F07kjufp67RJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "Pr3ToxLc1jTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sites_urlsL = [\"https://www.newsit.gr/eidhseis-tora/page/1/\",\n",
        "               \"https://www.naftemporiki.gr/newsroom/page/1/\",\n",
        "               \"https://www.dnews.gr/oles-oi-eidiseis?start=0\",\n",
        "               \"https://www.newsbomb.gr/oles-oi-eidhseis?page=1\",\n",
        "               \"https://www.lifo.gr/now?_wrapper_format=html&page=0\",\n",
        "               \"https://www.documentonews.gr/arxiki-selida/roi-eidiseon/page/1\",\n",
        "               \"https://www.tovima.gr/latest-news/page/1/\",\n",
        "               \"https://www.tanea.gr/allnews/page/1/\",\n",
        "               \"https://www.in.gr/latestnews/page/1/\",\n",
        "               \"https://www.iefimerida.gr/eidiseis?page=1\",\n",
        "               \"https://www.thetoc.gr/newsfeed/?page=1\",\n",
        "               \"https://www.athensvoice.gr/epikairotita/news/?pg=1\",\n",
        "               \"https://www.parapolitika.gr/roi-eidiseon/?pg=1\",\n",
        "               \"https://www.zougla.gr/ola/page/1/\"]"
      ],
      "metadata": {
        "id": "55d9Miin1I2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ΜΗΝ τρομάζετε με το function: εξηγείται διεξοδικά στο notebook κατασκευής του scraper, κι άλλωστε εσείς θα το χρησιμοποιήσετε όπως είναι.\n",
        "\n",
        "def get_articles_data(url):\n",
        "  # Ορισμός των headers για το requests\n",
        "  headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0\"\n",
        "    }\n",
        "  # Αίτημα στο server να φέρει την html από το url\n",
        "  response = requests.get(url, headers=headers)\n",
        "  # Μετατροπή του πηγαίου κώδικα της ιστοσελίδας σε αναζητήσιμο κείμενο (soup)\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  return soup"
      ],
      "metadata": {
        "id": "wW2FVmaK0_7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-E5g4kWCxdk-",
        "outputId": "dea376ed-b29a-485d-d894-33c0997195ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.newsit.gr/eidhseis-tora/page/1/: 16 articles\n",
            "https://www.naftemporiki.gr/newsroom/page/1/: 30 articles\n",
            "https://www.dnews.gr/oles-oi-eidiseis?start=0: 31 articles\n",
            "https://www.newsbomb.gr/oles-oi-eidhseis?page=1: 30 articles\n",
            "https://www.lifo.gr/now?_wrapper_format=html&page=0: 20 articles\n",
            "https://www.documentonews.gr/arxiki-selida/roi-eidiseon/page/1: 10 articles\n",
            "https://www.tovima.gr/latest-news/page/1/: 20 articles\n",
            "https://www.tanea.gr/allnews/page/1/: 30 articles\n",
            "https://www.in.gr/latestnews/page/1/: 30 articles\n",
            "https://www.iefimerida.gr/eidiseis?page=1: 10 articles\n",
            "https://www.thetoc.gr/newsfeed/?page=1: 11 articles\n",
            "https://www.athensvoice.gr/epikairotita/news/?pg=1: 10 articles\n",
            "https://www.parapolitika.gr/roi-eidiseon/?pg=1: 40 articles\n",
            "https://www.zougla.gr/ola/page/1/: 18 articles\n"
          ]
        }
      ],
      "source": [
        "for site_url in sites_urlsL:\n",
        "  soup = get_articles_data(site_url)\n",
        "  if \"newsit.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"article\")\n",
        "  elif \"naftemporiki.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"div\", {\"class\": \"item item-stream position-relative\"})\n",
        "  elif \"dnews.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"div\", class_=lambda c: c and \"item primary\" in c or c and \"item leading\" in c)\n",
        "  elif \"newsbomb.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"article\")\n",
        "  elif \"lifo.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"article\", {\"class\": \"row no-gutters mb-4 mb-lg-6\"})\n",
        "  elif \"documentonews.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"div\", {\"class\": \"item post loop\"})\n",
        "  elif \"tovima.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"div\", {\"class\": \"column is-full wrap-category-row\"})\n",
        "  elif \"tanea.gr\" in site_url:\n",
        "    articlesL = soup.find(\"div\", {\"class\": \"main-archive-articles\"}).find_all(\"div\", {\"class\": \"column is-full\"})\n",
        "  elif \"in.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"article\")\n",
        "  elif \"iefimerida.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"article\")\n",
        "  elif \"thetoc.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"div\", {\"class\": \"item-content\"})\n",
        "  elif \"athensvoice.gr\" in site_url:\n",
        "    articlesL = soup.find(\"div\", {\"class\": \"articles articles--singleColumn articles--large\"}).find_all(\"article\")\n",
        "  elif \"parapolitika.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"article\")\n",
        "  elif \"zougla.gr\" in site_url:\n",
        "    articlesL = soup.find_all(\"div\", {\"class\": \"article-wrapper\"})\n",
        "  else:\n",
        "    print(f\"{site_url} not found\")\n",
        "  print(f\"{site_url}: {len(articlesL)} articles\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Επίσης, προς διευκόλυνσή σας, έχω βρεί το tag/class για το block των άρθρων σε κάθε site, οπότε θα πάρετε τον κώδικα για το articlesL από το παραπάνω cell, ανάλογα με το site που θα δουλέψετε."
      ],
      "metadata": {
        "id": "zBA9j1OA2rn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Από την παραπάνω λίστα με τα sites θα πάρετε το url του πρώτου page της σελίδας με όλα τα άρθρα για το site που θα δουλέψετε."
      ],
      "metadata": {
        "id": "puwnX1KM4HZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μελετήστε μια φορά το notebook-οδηγό τρέχοντας όλα τα κελιά απ' την αρχή ως το τέλος και ΑΦΟΥ ΤΟ ΚΑΝΕΤΕ ΑΥΤΟ, φτιάξτε ένα αντίγραφο του notebook και αρχίστε να κάνετε τις αλλαγές που χρειάζονται.\n",
        "\n",
        "Θα βάλετε το url του site που διαλέξατε, τον κώδικα του articlesL και το μόνο που έχετε να κάνετε είναι να βρείτε τα tags/sections για τα elements των δεδομένων που φέρουν τα άρθρα.\n",
        "\n",
        "Καλό θα ήταν να φτιάξετε έναν ολοκληρωμένο scraper που θα δουλεύει δηλαδή και στις σελίδες των κατηγοριών και της αναζήτησης (ιδιαίτερα της αναζήτησης), αλλά αν κουραστείτε κάνετε έστω τον scraper να δουλεύει σωστά για τις σελίδες με όλα τα άρθρα."
      ],
      "metadata": {
        "id": "N2lLlmGx4zeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ΓΙΑ ΝΑ ΔΙΑΣΦΑΛΙΣΟΥΜΕ ΟΤΙ ΔΕΝ ΘΑ ΚΑΝΕΤΕ 2 ΑΤΟΜΑ ΤΟ ΙΔΙΟ SITE,\n",
        "\n",
        "δηλώστε εδώ ποιο site δουλεύετε και επιλέξτε να δουλέψετε με ένα site που δεν έχει δηλώσει άλλος/άλλη: https://docs.google.com/spreadsheets/d/1onHp3ua1944SJGrBXVt3zJ16wrWMUBZOM2PD4AQtK50/edit?usp=sharing"
      ],
      "metadata": {
        "id": "Ixk_O3KR9RKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n"
      ],
      "metadata": {
        "id": "jaGUMnOT6WY8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_webpage_soup(url):\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: {response.status_code}\")\n",
        "        return None\n",
        "    else:\n",
        "        print(f\"{url} was scraped successfully\")\n",
        "        return BeautifulSoup(response.text, 'html.parser')\n",
        ""
      ],
      "metadata": {
        "id": "MbvduhmAEciU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_teaser_elements_from_articlesL(articlesL):\n",
        "  articles_dataL = []\n",
        "  for article in articlesL:\n",
        "    try:\n",
        "      title = article.find(\"a\", {\"class\": \"py-4 mainlink\"}).text.strip()\n",
        "    except:\n",
        "      try:\n",
        "        title = article.find(\"p\", class_=lambda c: c and \"title is-5 medium_title\" in c).text.strip()\n",
        "      except:\n",
        "        title=\"\"\n",
        "    try:\n",
        "      article_url = article.find(\"div\", {\"class\": \"content\"}).a[\"href\"]\n",
        "    except:\n",
        "      try:\n",
        "        article_url = article.find(\"a\", {\"class\": \"py-4 mainlink\"})[\"href\"]\n",
        "      except:\n",
        "        article_url=\"\"\n",
        "\n",
        "    try:\n",
        "      datetime_str = article.find(\"time\")[\"datetime\"]\n",
        "      date_str = datetime_str.split(\"T\")[0]\n",
        "      time_str = datetime_str.split(\"T\")[1].split(\"+\")[0]\n",
        "    except:\n",
        "      try:\n",
        "        datetime_str = article.find(\"div\", {\"class\": \"card-date\"}).text.strip()\n",
        "        dt_partsL = datetime_str.split(\".\")\n",
        "        date_str = f\"{dt_partsL[2]}-{dt_partsL[1]}-{dt_partsL[0]}\"\n",
        "        time_str = \"\"\n",
        "      except:\n",
        "        date_str = \"\"\n",
        "        time_str = \"\"\n",
        "\n",
        "    try:\n",
        "      section = article.find(\"p\", class_=lambda c: c and \"subtitle\" in c).text.strip()\n",
        "    except:\n",
        "      section = \"\"\n",
        "\n",
        "    try:\n",
        "      excerpt = article.find(\"div\", class_= lambda c: c and \"lead\" in c).text.strip()\n",
        "    except:\n",
        "      excerpt = \"\"\n",
        "\n",
        "    try:\n",
        "      author = article.find(\"span\", {\"class\":\"mb-2 author-link\"}).text.strip()\n",
        "    except:\n",
        "      author = \"\"\n",
        "\n",
        "    articleD = {\"title\": title, \"article_url\": article_url, \"date\": date_str, \"time\": time_str, \"section\": section, \"excerpt\": excerpt, \"author\": author}\n",
        "\n",
        "\n",
        "    articles_dataL.append(articleD)\n",
        "\n",
        "  return articles_dataL"
      ],
      "metadata": {
        "id": "KidmIzgDEdSj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_documento_teaser_pages(archive_name, start_page_nbr, end_page_nbr):\n",
        "  all_articles_dataL = []\n",
        "  print(f\"\\rScraping started\", end=\"\")\n",
        "def scrape_documento_teaser_pages(archive_name, start_page_nbr, end_page_nbr):\n",
        "  all_articles_dataL = []\n",
        "  print(f\"\\rScraping started\", end=\"\")\n",
        "  for page_nbr in range(start_page_nbr, end_page_nbr+1):\n",
        "    url = f\"https://www.documentonews.gr/arxiki-selida/roi-eidiseon/page/{page_nbr}\"\n",
        "    print(f\"\\rScraping page {page_nbr}...\", end=\"\") #Corrected this line\n",
        "    soup = get_webpage_soup(url) #Corrected this line, added missing =\n",
        "    articlesL = soup.find_all(\"div\", {\"class\": \"nx -article\"})\n",
        "    page_articles_dataL = get_teaser_elements_from_articlesL(articlesL)\n",
        "    all_articles_dataL.extend(page_articles_dataL) #Corrected this line, changed articles_dataL to all_articles_dataL\n",
        "    delay=random.uniform(1,3)\n",
        "    time.sleep(delay)\n",
        "  df=pd.DataFrame(all_articles_dataL) #Corrected this line, changed articles_dataL to all_articles_dataL and removed pd.pd\n",
        "  print(f\"\\rScraping completed. Fetshed {len(df)} articles.\")\n",
        "  return df\n",
        ""
      ],
      "metadata": {
        "id": "f3UND_EqpcKz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "muNXJf_cNEfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "articles_data = scrape_documento_teaser_pages(\"documentonews\", 1, 2)\n",
        "ukraine_df = scrape_documento_teaser_pages(\"search/Ουκρανία\", 1, 2)\n",
        "ukraine_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "leViGLQRJKql",
        "outputId": "e4629375-3960-412c-a8b8-7de56905cb95"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...https://www.documentonews.gr/arxiki-selida/roi-eidiseon/page/1 was scraped successfully\n",
            "Scraping page 2...https://www.documentonews.gr/arxiki-selida/roi-eidiseon/page/2 was scraped successfully\n",
            "Scraping completed. Fetshed 0 articles.\n",
            "Scraping page 1...https://www.documentonews.gr/arxiki-selida/roi-eidiseon/page/1 was scraped successfully\n",
            "Scraping page 2...https://www.documentonews.gr/arxiki-selida/roi-eidiseon/page/2 was scraped successfully\n",
            "Scraping completed. Fetshed 0 articles.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: []\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c1150e7-4c4c-4fce-9094-3071949321c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c1150e7-4c4c-4fce-9094-3071949321c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c1150e7-4c4c-4fce-9094-3071949321c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c1150e7-4c4c-4fce-9094-3071949321c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c3195041-f119-4cdd-b5dd-181db4f5c1b9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ukraine_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c3195041-f119-4cdd-b5dd-181db4f5c1b9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ukraine_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ukraine_df",
              "summary": "{\n  \"name\": \"ukraine_df\",\n  \"rows\": 0,\n  \"fields\": []\n}"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZYvEmNKpkQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEY77S8BEdQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3WkhoGsCEdMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgoNYhzqEdHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0KdTB7pEc_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "96CEzlgDEc2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}